// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package components

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/jamelt/openai-api/internal/utils"
)

type CreateFineTuningJobRequestModel2 string

const (
	CreateFineTuningJobRequestModel2Babbage002 CreateFineTuningJobRequestModel2 = "babbage-002"
	CreateFineTuningJobRequestModel2Davinci002 CreateFineTuningJobRequestModel2 = "davinci-002"
	CreateFineTuningJobRequestModel2Gpt35Turbo CreateFineTuningJobRequestModel2 = "gpt-3.5-turbo"
	CreateFineTuningJobRequestModel2Gpt4oMini  CreateFineTuningJobRequestModel2 = "gpt-4o-mini"
)

func (e CreateFineTuningJobRequestModel2) ToPointer() *CreateFineTuningJobRequestModel2 {
	return &e
}
func (e *CreateFineTuningJobRequestModel2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "babbage-002":
		fallthrough
	case "davinci-002":
		fallthrough
	case "gpt-3.5-turbo":
		fallthrough
	case "gpt-4o-mini":
		*e = CreateFineTuningJobRequestModel2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateFineTuningJobRequestModel2: %v", v)
	}
}

type CreateFineTuningJobRequestModelType string

const (
	CreateFineTuningJobRequestModelTypeStr                              CreateFineTuningJobRequestModelType = "str"
	CreateFineTuningJobRequestModelTypeCreateFineTuningJobRequestModel2 CreateFineTuningJobRequestModelType = "CreateFineTuningJobRequest_model_2"
)

// CreateFineTuningJobRequestModel - The name of the model to fine-tune. You can select one of the
// [supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).
type CreateFineTuningJobRequestModel struct {
	Str                              *string
	CreateFineTuningJobRequestModel2 *CreateFineTuningJobRequestModel2

	Type CreateFineTuningJobRequestModelType
}

func CreateCreateFineTuningJobRequestModelStr(str string) CreateFineTuningJobRequestModel {
	typ := CreateFineTuningJobRequestModelTypeStr

	return CreateFineTuningJobRequestModel{
		Str:  &str,
		Type: typ,
	}
}

func CreateCreateFineTuningJobRequestModelCreateFineTuningJobRequestModel2(createFineTuningJobRequestModel2 CreateFineTuningJobRequestModel2) CreateFineTuningJobRequestModel {
	typ := CreateFineTuningJobRequestModelTypeCreateFineTuningJobRequestModel2

	return CreateFineTuningJobRequestModel{
		CreateFineTuningJobRequestModel2: &createFineTuningJobRequestModel2,
		Type:                             typ,
	}
}

func (u *CreateFineTuningJobRequestModel) UnmarshalJSON(data []byte) error {

	var str string = ""
	if err := utils.UnmarshalJSON(data, &str, "", true, true); err == nil {
		u.Str = &str
		u.Type = CreateFineTuningJobRequestModelTypeStr
		return nil
	}

	var createFineTuningJobRequestModel2 CreateFineTuningJobRequestModel2 = CreateFineTuningJobRequestModel2("")
	if err := utils.UnmarshalJSON(data, &createFineTuningJobRequestModel2, "", true, true); err == nil {
		u.CreateFineTuningJobRequestModel2 = &createFineTuningJobRequestModel2
		u.Type = CreateFineTuningJobRequestModelTypeCreateFineTuningJobRequestModel2
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for CreateFineTuningJobRequestModel", string(data))
}

func (u CreateFineTuningJobRequestModel) MarshalJSON() ([]byte, error) {
	if u.Str != nil {
		return utils.MarshalJSON(u.Str, "", true)
	}

	if u.CreateFineTuningJobRequestModel2 != nil {
		return utils.MarshalJSON(u.CreateFineTuningJobRequestModel2, "", true)
	}

	return nil, errors.New("could not marshal union type CreateFineTuningJobRequestModel: all fields are null")
}

type BatchSize1 string

const (
	BatchSize1Auto BatchSize1 = "auto"
)

func (e BatchSize1) ToPointer() *BatchSize1 {
	return &e
}
func (e *BatchSize1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		*e = BatchSize1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for BatchSize1: %v", v)
	}
}

type BatchSizeType string

const (
	BatchSizeTypeBatchSize1 BatchSizeType = "batch_size_1"
	BatchSizeTypeInteger    BatchSizeType = "integer"
)

// BatchSize - Number of examples in each batch. A larger batch size means that model parameters
// are updated less frequently, but with lower variance.
type BatchSize struct {
	BatchSize1 *BatchSize1
	Integer    *int64

	Type BatchSizeType
}

func CreateBatchSizeBatchSize1(batchSize1 BatchSize1) BatchSize {
	typ := BatchSizeTypeBatchSize1

	return BatchSize{
		BatchSize1: &batchSize1,
		Type:       typ,
	}
}

func CreateBatchSizeInteger(integer int64) BatchSize {
	typ := BatchSizeTypeInteger

	return BatchSize{
		Integer: &integer,
		Type:    typ,
	}
}

func (u *BatchSize) UnmarshalJSON(data []byte) error {

	var batchSize1 BatchSize1 = BatchSize1("")
	if err := utils.UnmarshalJSON(data, &batchSize1, "", true, true); err == nil {
		u.BatchSize1 = &batchSize1
		u.Type = BatchSizeTypeBatchSize1
		return nil
	}

	var integer int64 = int64(0)
	if err := utils.UnmarshalJSON(data, &integer, "", true, true); err == nil {
		u.Integer = &integer
		u.Type = BatchSizeTypeInteger
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for BatchSize", string(data))
}

func (u BatchSize) MarshalJSON() ([]byte, error) {
	if u.BatchSize1 != nil {
		return utils.MarshalJSON(u.BatchSize1, "", true)
	}

	if u.Integer != nil {
		return utils.MarshalJSON(u.Integer, "", true)
	}

	return nil, errors.New("could not marshal union type BatchSize: all fields are null")
}

type LearningRateMultiplier1 string

const (
	LearningRateMultiplier1Auto LearningRateMultiplier1 = "auto"
)

func (e LearningRateMultiplier1) ToPointer() *LearningRateMultiplier1 {
	return &e
}
func (e *LearningRateMultiplier1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		*e = LearningRateMultiplier1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LearningRateMultiplier1: %v", v)
	}
}

type LearningRateMultiplierType string

const (
	LearningRateMultiplierTypeLearningRateMultiplier1 LearningRateMultiplierType = "learning_rate_multiplier_1"
	LearningRateMultiplierTypeNumber                  LearningRateMultiplierType = "number"
)

// LearningRateMultiplier - Scaling factor for the learning rate. A smaller learning rate may be useful to avoid
// overfitting.
type LearningRateMultiplier struct {
	LearningRateMultiplier1 *LearningRateMultiplier1
	Number                  *float64

	Type LearningRateMultiplierType
}

func CreateLearningRateMultiplierLearningRateMultiplier1(learningRateMultiplier1 LearningRateMultiplier1) LearningRateMultiplier {
	typ := LearningRateMultiplierTypeLearningRateMultiplier1

	return LearningRateMultiplier{
		LearningRateMultiplier1: &learningRateMultiplier1,
		Type:                    typ,
	}
}

func CreateLearningRateMultiplierNumber(number float64) LearningRateMultiplier {
	typ := LearningRateMultiplierTypeNumber

	return LearningRateMultiplier{
		Number: &number,
		Type:   typ,
	}
}

func (u *LearningRateMultiplier) UnmarshalJSON(data []byte) error {

	var learningRateMultiplier1 LearningRateMultiplier1 = LearningRateMultiplier1("")
	if err := utils.UnmarshalJSON(data, &learningRateMultiplier1, "", true, true); err == nil {
		u.LearningRateMultiplier1 = &learningRateMultiplier1
		u.Type = LearningRateMultiplierTypeLearningRateMultiplier1
		return nil
	}

	var number float64 = float64(0)
	if err := utils.UnmarshalJSON(data, &number, "", true, true); err == nil {
		u.Number = &number
		u.Type = LearningRateMultiplierTypeNumber
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for LearningRateMultiplier", string(data))
}

func (u LearningRateMultiplier) MarshalJSON() ([]byte, error) {
	if u.LearningRateMultiplier1 != nil {
		return utils.MarshalJSON(u.LearningRateMultiplier1, "", true)
	}

	if u.Number != nil {
		return utils.MarshalJSON(u.Number, "", true)
	}

	return nil, errors.New("could not marshal union type LearningRateMultiplier: all fields are null")
}

type NEpochs1 string

const (
	NEpochs1Auto NEpochs1 = "auto"
)

func (e NEpochs1) ToPointer() *NEpochs1 {
	return &e
}
func (e *NEpochs1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		*e = NEpochs1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for NEpochs1: %v", v)
	}
}

type NEpochsType string

const (
	NEpochsTypeNEpochs1 NEpochsType = "n_epochs_1"
	NEpochsTypeInteger  NEpochsType = "integer"
)

// NEpochs - The number of epochs to train the model for. An epoch refers to one full cycle
// through the training dataset.
type NEpochs struct {
	NEpochs1 *NEpochs1
	Integer  *int64

	Type NEpochsType
}

func CreateNEpochsNEpochs1(nEpochs1 NEpochs1) NEpochs {
	typ := NEpochsTypeNEpochs1

	return NEpochs{
		NEpochs1: &nEpochs1,
		Type:     typ,
	}
}

func CreateNEpochsInteger(integer int64) NEpochs {
	typ := NEpochsTypeInteger

	return NEpochs{
		Integer: &integer,
		Type:    typ,
	}
}

func (u *NEpochs) UnmarshalJSON(data []byte) error {

	var nEpochs1 NEpochs1 = NEpochs1("")
	if err := utils.UnmarshalJSON(data, &nEpochs1, "", true, true); err == nil {
		u.NEpochs1 = &nEpochs1
		u.Type = NEpochsTypeNEpochs1
		return nil
	}

	var integer int64 = int64(0)
	if err := utils.UnmarshalJSON(data, &integer, "", true, true); err == nil {
		u.Integer = &integer
		u.Type = NEpochsTypeInteger
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for NEpochs", string(data))
}

func (u NEpochs) MarshalJSON() ([]byte, error) {
	if u.NEpochs1 != nil {
		return utils.MarshalJSON(u.NEpochs1, "", true)
	}

	if u.Integer != nil {
		return utils.MarshalJSON(u.Integer, "", true)
	}

	return nil, errors.New("could not marshal union type NEpochs: all fields are null")
}

// Hyperparameters - The hyperparameters used for the fine-tuning job.
type Hyperparameters struct {
	// Number of examples in each batch. A larger batch size means that model parameters
	// are updated less frequently, but with lower variance.
	//
	BatchSize *BatchSize `json:"batch_size,omitempty"`
	// Scaling factor for the learning rate. A smaller learning rate may be useful to avoid
	// overfitting.
	//
	LearningRateMultiplier *LearningRateMultiplier `json:"learning_rate_multiplier,omitempty"`
	// The number of epochs to train the model for. An epoch refers to one full cycle
	// through the training dataset.
	//
	NEpochs *NEpochs `json:"n_epochs,omitempty"`
}

func (o *Hyperparameters) GetBatchSize() *BatchSize {
	if o == nil {
		return nil
	}
	return o.BatchSize
}

func (o *Hyperparameters) GetLearningRateMultiplier() *LearningRateMultiplier {
	if o == nil {
		return nil
	}
	return o.LearningRateMultiplier
}

func (o *Hyperparameters) GetNEpochs() *NEpochs {
	if o == nil {
		return nil
	}
	return o.NEpochs
}

type Type1 string

const (
	Type1Wandb Type1 = "wandb"
)

func (e Type1) ToPointer() *Type1 {
	return &e
}
func (e *Type1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wandb":
		*e = Type1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Type1: %v", v)
	}
}

type CreateFineTuningJobRequestTypeType string

const (
	CreateFineTuningJobRequestTypeTypeType1 CreateFineTuningJobRequestTypeType = "type_1"
)

// CreateFineTuningJobRequestType - The type of integration to enable. Currently, only "wandb" (Weights and Biases) is supported.
type CreateFineTuningJobRequestType struct {
	Type1 *Type1

	Type CreateFineTuningJobRequestTypeType
}

func CreateCreateFineTuningJobRequestTypeType1(type1 Type1) CreateFineTuningJobRequestType {
	typ := CreateFineTuningJobRequestTypeTypeType1

	return CreateFineTuningJobRequestType{
		Type1: &type1,
		Type:  typ,
	}
}

func (u *CreateFineTuningJobRequestType) UnmarshalJSON(data []byte) error {

	var type1 Type1 = Type1("")
	if err := utils.UnmarshalJSON(data, &type1, "", true, true); err == nil {
		u.Type1 = &type1
		u.Type = CreateFineTuningJobRequestTypeTypeType1
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for CreateFineTuningJobRequestType", string(data))
}

func (u CreateFineTuningJobRequestType) MarshalJSON() ([]byte, error) {
	if u.Type1 != nil {
		return utils.MarshalJSON(u.Type1, "", true)
	}

	return nil, errors.New("could not marshal union type CreateFineTuningJobRequestType: all fields are null")
}

// CreateFineTuningJobRequestWandb - The settings for your integration with Weights and Biases. This payload specifies the project that
// metrics will be sent to. Optionally, you can set an explicit display name for your run, add tags
// to your run, and set a default entity (team, username, etc) to be associated with your run.
type CreateFineTuningJobRequestWandb struct {
	// The name of the project that the new run will be created under.
	//
	Project string `json:"project"`
	// A display name to set for the run. If not set, we will use the Job ID as the name.
	//
	Name *string `json:"name,omitempty"`
	// The entity to use for the run. This allows you to set the team or username of the WandB user that you would
	// like associated with the run. If not set, the default entity for the registered WandB API key is used.
	//
	Entity *string `json:"entity,omitempty"`
	// A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some
	// default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}", "openai/{ftjob-abcdef}".
	//
	Tags []string `json:"tags,omitempty"`
}

func (o *CreateFineTuningJobRequestWandb) GetProject() string {
	if o == nil {
		return ""
	}
	return o.Project
}

func (o *CreateFineTuningJobRequestWandb) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *CreateFineTuningJobRequestWandb) GetEntity() *string {
	if o == nil {
		return nil
	}
	return o.Entity
}

func (o *CreateFineTuningJobRequestWandb) GetTags() []string {
	if o == nil {
		return nil
	}
	return o.Tags
}

type Integrations struct {
	// The type of integration to enable. Currently, only "wandb" (Weights and Biases) is supported.
	//
	Type CreateFineTuningJobRequestType `json:"type"`
	// The settings for your integration with Weights and Biases. This payload specifies the project that
	// metrics will be sent to. Optionally, you can set an explicit display name for your run, add tags
	// to your run, and set a default entity (team, username, etc) to be associated with your run.
	//
	Wandb CreateFineTuningJobRequestWandb `json:"wandb"`
}

func (o *Integrations) GetType() CreateFineTuningJobRequestType {
	if o == nil {
		return CreateFineTuningJobRequestType{}
	}
	return o.Type
}

func (o *Integrations) GetWandb() CreateFineTuningJobRequestWandb {
	if o == nil {
		return CreateFineTuningJobRequestWandb{}
	}
	return o.Wandb
}

type CreateFineTuningJobRequest struct {
	// The name of the model to fine-tune. You can select one of the
	// [supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).
	//
	Model CreateFineTuningJobRequestModel `json:"model"`
	// The ID of an uploaded file that contains training data.
	//
	// See [upload file](/docs/api-reference/files/create) for how to upload a file.
	//
	// Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.
	//
	// The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.
	//
	// See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
	//
	TrainingFile string `json:"training_file"`
	// The hyperparameters used for the fine-tuning job.
	Hyperparameters *Hyperparameters `json:"hyperparameters,omitempty"`
	// A string of up to 64 characters that will be added to your fine-tuned model name.
	//
	// For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.
	//
	Suffix *string `default:"null" json:"suffix"`
	// The ID of an uploaded file that contains validation data.
	//
	// If you provide this file, the data is used to generate validation
	// metrics periodically during fine-tuning. These metrics can be viewed in
	// the fine-tuning results file.
	// The same data should not be present in both train and validation files.
	//
	// Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.
	//
	// See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
	//
	ValidationFile *string `json:"validation_file,omitempty"`
	// A list of integrations to enable for your fine-tuning job.
	Integrations []Integrations `json:"integrations,omitempty"`
	// The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
	// If a seed is not specified, one will be generated for you.
	//
	Seed *int64 `json:"seed,omitempty"`
}

func (c CreateFineTuningJobRequest) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateFineTuningJobRequest) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateFineTuningJobRequest) GetModel() CreateFineTuningJobRequestModel {
	if o == nil {
		return CreateFineTuningJobRequestModel{}
	}
	return o.Model
}

func (o *CreateFineTuningJobRequest) GetTrainingFile() string {
	if o == nil {
		return ""
	}
	return o.TrainingFile
}

func (o *CreateFineTuningJobRequest) GetHyperparameters() *Hyperparameters {
	if o == nil {
		return nil
	}
	return o.Hyperparameters
}

func (o *CreateFineTuningJobRequest) GetSuffix() *string {
	if o == nil {
		return nil
	}
	return o.Suffix
}

func (o *CreateFineTuningJobRequest) GetValidationFile() *string {
	if o == nil {
		return nil
	}
	return o.ValidationFile
}

func (o *CreateFineTuningJobRequest) GetIntegrations() []Integrations {
	if o == nil {
		return nil
	}
	return o.Integrations
}

func (o *CreateFineTuningJobRequest) GetSeed() *int64 {
	if o == nil {
		return nil
	}
	return o.Seed
}
