// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package components

import (
	"encoding/json"
	"fmt"
)

// TruncationObjectType - The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.
type TruncationObjectType string

const (
	TruncationObjectTypeAuto         TruncationObjectType = "auto"
	TruncationObjectTypeLastMessages TruncationObjectType = "last_messages"
)

func (e TruncationObjectType) ToPointer() *TruncationObjectType {
	return &e
}
func (e *TruncationObjectType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "last_messages":
		*e = TruncationObjectType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TruncationObjectType: %v", v)
	}
}

// TruncationObject - Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.
type TruncationObject struct {
	// The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.
	Type TruncationObjectType `json:"type"`
	// The number of most recent messages from the thread when constructing the context for the run.
	LastMessages *int64 `json:"last_messages,omitempty"`
}

func (o *TruncationObject) GetType() TruncationObjectType {
	if o == nil {
		return TruncationObjectType("")
	}
	return o.Type
}

func (o *TruncationObject) GetLastMessages() *int64 {
	if o == nil {
		return nil
	}
	return o.LastMessages
}
