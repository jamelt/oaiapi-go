// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package operations

import (
	"encoding/json"
	"fmt"
	"github.com/jamelt/openai-api/models/components"
)

// Endpoint - The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.
type Endpoint string

const (
	EndpointRootV1ChatCompletions Endpoint = "/v1/chat/completions"
	EndpointRootV1Embeddings      Endpoint = "/v1/embeddings"
	EndpointRootV1Completions     Endpoint = "/v1/completions"
)

func (e Endpoint) ToPointer() *Endpoint {
	return &e
}
func (e *Endpoint) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "/v1/chat/completions":
		fallthrough
	case "/v1/embeddings":
		fallthrough
	case "/v1/completions":
		*e = Endpoint(v)
		return nil
	default:
		return fmt.Errorf("invalid value for Endpoint: %v", v)
	}
}

// CompletionWindow - The time frame within which the batch should be processed. Currently only `24h` is supported.
type CompletionWindow string

const (
	CompletionWindowTwentyFourh CompletionWindow = "24h"
)

func (e CompletionWindow) ToPointer() *CompletionWindow {
	return &e
}
func (e *CompletionWindow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "24h":
		*e = CompletionWindow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompletionWindow: %v", v)
	}
}

type CreateBatchRequestBody struct {
	// The ID of an uploaded file that contains requests for the new batch.
	//
	// See [upload file](/docs/api-reference/files/create) for how to upload a file.
	//
	// Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 100 MB in size.
	//
	InputFileID string `json:"input_file_id"`
	// The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.
	Endpoint Endpoint `json:"endpoint"`
	// The time frame within which the batch should be processed. Currently only `24h` is supported.
	CompletionWindow CompletionWindow `json:"completion_window"`
	// Optional custom metadata for the batch.
	Metadata map[string]string `json:"metadata,omitempty"`
}

func (o *CreateBatchRequestBody) GetInputFileID() string {
	if o == nil {
		return ""
	}
	return o.InputFileID
}

func (o *CreateBatchRequestBody) GetEndpoint() Endpoint {
	if o == nil {
		return Endpoint("")
	}
	return o.Endpoint
}

func (o *CreateBatchRequestBody) GetCompletionWindow() CompletionWindow {
	if o == nil {
		return CompletionWindow("")
	}
	return o.CompletionWindow
}

func (o *CreateBatchRequestBody) GetMetadata() map[string]string {
	if o == nil {
		return nil
	}
	return o.Metadata
}

type CreateBatchResponse struct {
	HTTPMeta components.HTTPMetadata `json:"-"`
	// Batch created successfully.
	Batch *components.Batch
}

func (o *CreateBatchResponse) GetHTTPMeta() components.HTTPMetadata {
	if o == nil {
		return components.HTTPMetadata{}
	}
	return o.HTTPMeta
}

func (o *CreateBatchResponse) GetBatch() *components.Batch {
	if o == nil {
		return nil
	}
	return o.Batch
}
